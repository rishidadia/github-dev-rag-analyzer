{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPyZikINW+MKrZZaqe5AVKS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rishidadia/github-dev-rag-analyzer/blob/main/GithubRag.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DOWNLOADS, IMPORTS\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "mzuyKlPOa0G7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pIHh5hcnOUsD"
      },
      "outputs": [],
      "source": [
        "!pip install -U llama-index\n",
        "!pip install sentence-transformers\n",
        "!pip install PyGithub\n",
        "!pip install -U llama-index-embeddings-huggingface"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import Document, VectorStoreIndex\n",
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "from github import Github"
      ],
      "metadata": {
        "id": "MeserckOQKy-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SETTING UP GITHUB LIRARY"
      ],
      "metadata": {
        "id": "uhgeSjPIbBQS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "token_name=userdata.get('GITHUB_TOKEN')\n",
        "g=Github(token_name)\n",
        "print(g.get_rate_limit().resources.core)\n",
        "# print(token_name)"
      ],
      "metadata": {
        "id": "yoKrzZcvS-fY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# user_name=input(\"Enter username\")\n",
        "user_name='viraj-ap'\n",
        "user=g.get_user(user_name)"
      ],
      "metadata": {
        "id": "3D_BEXcThHfK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CREATING DOCUMENTS FOR THE PULLED DATA"
      ],
      "metadata": {
        "id": "fsgqkkPhbGtY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import Document\n",
        "def make_doc(\n",
        "    *,\n",
        "    text:str,\n",
        "    node_type:str,\n",
        "    username:str,\n",
        "    repo:str|None=None,\n",
        "    year:int|None=None,\n",
        "    extra_meta:str|None=None,\n",
        "):\n",
        "  metadata={\n",
        "      \"type\":node_type,\n",
        "      \"username\":username,\n",
        "  }\n",
        "  if repo:\n",
        "    metadata['repo']=repo\n",
        "  if year:\n",
        "    metadata['year']=year\n",
        "  if extra_meta:\n",
        "    metadata['extra_meta']=extra_meta\n",
        "  return Document(\n",
        "      text=text.strip(),\n",
        "      metadata=metadata\n",
        "  )"
      ],
      "metadata": {
        "id": "BzMYrhf9WOiG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "profile_text=f\"\"\"\n",
        "  TYPE:UserProfile\n",
        "  USERNAME:{user.login}\n",
        "\n",
        "  Name:{user.name}\n",
        "  Bio:{user.bio}\n",
        "  Company:{user.company}\n",
        "  Location:{user.location}\n",
        "  Public Repositiries:{user.public_repos}\n",
        "  Followers:{user.followers}\n",
        "  Following:{user.following}\n",
        "\n",
        "  Summary:\n",
        "  Doc for Github profile and it's public identity\n",
        "\"\"\"\n",
        "user_profile_doc=make_doc(\n",
        "    text=profile_text,\n",
        "    node_type=\"user_profile\",\n",
        "    username=user.login\n",
        ")"
      ],
      "metadata": {
        "id": "uJiKVsZeYNqh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "repo_docs=[]\n",
        "readme_docs=[]\n",
        "commit_docs=[]\n",
        "for repo in user.get_repos():\n",
        "  #-----REPO SUMMARY-------\n",
        "  repo_summary_text=f\"\"\"\n",
        "      TYPE:RepoSummary\n",
        "      REPO:{repo.name}\n",
        "\n",
        "      Description:{repo.description}\n",
        "      Primary Language:{repo.language}\n",
        "      Forks:{repo.forks_count}\n",
        "      Open Issues:{repo.open_issues_count}\n",
        "      Created at:{repo.created_at}\n",
        "      Last updated:{repo.updated_at}\n",
        "\n",
        "      Summary:\n",
        "      This repo represents a core repo made and maintained by the user\n",
        "  \"\"\"\n",
        "  repo_summary_doc=make_doc(\n",
        "      text=repo_summary_text,\n",
        "      node_type=\"repo_summary\",\n",
        "      username=user.login,\n",
        "      repo=repo.name\n",
        "  )\n",
        "  repo_docs.append(repo_summary_doc)\n",
        "\n",
        "  #----README SUMMARY----\n",
        "  try:\n",
        "    readme=repo.get_readme().decoded_content.decode('utf-8')[:4000]\n",
        "  except:\n",
        "    readme=\"ReadMe not available\"\n",
        "\n",
        "  readme_summary_text=f\"\"\"\n",
        "      TYPE:ReadMESummary\n",
        "      REPO:{repo.name}\n",
        "\n",
        "      README CONTENT:{readme}\n",
        "\n",
        "      Sumarry: This document explains the intent, scope, tech stack and notes from the user regarding the repo\n",
        "  \"\"\"\n",
        "\n",
        "  readme_summary_doc=make_doc(\n",
        "      text=readme_summary_text,\n",
        "      node_type=\"repo_documentation\",\n",
        "      username=user.login,\n",
        "      repo=repo.name,\n",
        "  )\n",
        "  readme_docs.append(readme_summary_doc)\n",
        "\n",
        "\n",
        "  #---COMMIT SUMMARY---\n",
        "  commit_messages=[]\n",
        "  additions=deletions=0\n",
        "\n",
        "  for commit in repo.get_commits()[:50]:\n",
        "      commit_messages.append(commit.commit.message.split(\"\\n\")[0])\n",
        "      if commit.stats:\n",
        "          additions += commit.stats.additions\n",
        "          deletions += commit.stats.deletions\n",
        "\n",
        "  commit_behavior_text = f\"\"\"\n",
        "  TYPE: CommitBehavior\n",
        "  REPO: {repo.name}\n",
        "\n",
        "  Total Commits Analyzed: {len(commit_messages)}\n",
        "  Total Additions: {additions}\n",
        "  Total Deletions: {deletions}\n",
        "\n",
        "  Sample Commit Messages:\n",
        "  - \"\"\" + \"\\n- \".join(commit_messages[:10]) + \"\"\"\n",
        "\n",
        "  Analysis:\n",
        "  This document reflects the coding activity, work intensity, and contribution depth of the user.\n",
        "  \"\"\"\n",
        "\n",
        "  commit_behavior_doc = make_doc(\n",
        "      text=commit_behavior_text,\n",
        "      node_type=\"commit_behavior\",\n",
        "      username=user.login,\n",
        "      repo=repo.name\n",
        "  )\n",
        "  commit_docs.append(commit_behavior_doc)\n"
      ],
      "metadata": {
        "id": "ao3WCtwuajsI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_docs=(\n",
        "    [user_profile_doc]+\n",
        "    repo_docs+\n",
        "    readme_docs+\n",
        "    commit_docs\n",
        ")"
      ],
      "metadata": {
        "id": "mPZvo0Ze51Jv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(all_docs[0]))\n",
        "print(isinstance(all_docs[0], list))"
      ],
      "metadata": {
        "id": "pdNfc85jVio8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SUMMARY FOR THE USER ACCOUNT"
      ],
      "metadata": {
        "id": "gMU27HIybSIM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evidence_bloc=repo_docs+readme_docs+commit_docs\n",
        "evidence_text=\"\\n\\n--\\n\\n\".join(doc.text for doc in evidence_bloc[:15])"
      ],
      "metadata": {
        "id": "_uagO4M9U-ob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "allowed_domains=[\n",
        "    \"machine learning\",\n",
        "    \"automation\",\n",
        "    \"data science\",\n",
        "    \"backend systems\",\n",
        "    \"frontend\",\n",
        "    \"devops\",\n",
        "    \"mlops\",\n",
        "    \"fintech\",\n",
        "    \"cybersecurity\",\n",
        "    \"embedded systems\",\n",
        "    \"full stack app developer\",\n",
        "    \"full stack web developer\",\n",
        "    \"iot\",\n",
        "    \"blockchain\",\n",
        "    \"ar/vr\",\n",
        "    \"robotics\",\n",
        "    \"quantum computing\"\n",
        "]"
      ],
      "metadata": {
        "id": "kYUODvmtiv36"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "domain_prompt=f\"\"\"\n",
        "  You are a technical evaluator.\n",
        "  You are provided with repository level information that includes readme, commit history and overall type of repository.\n",
        "\n",
        "  You're task is to evaluate domain coverage, what in that domain is covered, and how deep they have gone in that domain.\n",
        "  Accordingly signal as Beginner/ Intermediate or Pro.\n",
        "  You are to give evidence for this by calling which repo you are referring to and what in that repo made you signal what you did.\n",
        "  This evidence is to be positive only, even if someone is a beginner, you will not mention the things that are absent, only what is present.\n",
        "  Also mention the number of repos you analyzed in the beginning.\n",
        "\n",
        "  Allowed domains={allowed_domains}\n",
        "\n",
        "  You will also mention the programming languages used in order of usage.\n",
        "\n",
        "  Lastly from all this information, you will give what market or sector the user is best fit to work in. What sort of companies can the user target\n",
        "  based on their level of understanding of the domain. The level of the company has to be synonymous the skill level of the user. A beginner will probably not get into MAANG.\n",
        "\n",
        "  This is the information given to you of the user:{evidence_text}\n",
        "\n",
        "  Output format(strict):\n",
        "  domain_name:level(Beginner/ Intermediate or Pro)\n",
        "  proof for it\n",
        "  what in that specific domain has been covered by the username.\n",
        "\n",
        "  Frequently used programming languages:\n",
        "  language:what is coded in that language\n",
        "\n",
        "  Industry fit:\n",
        "  What industry can they work in.\n",
        "  What companies can they aim for.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "VXTNh5oZhj2N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q google-generativeai"
      ],
      "metadata": {
        "id": "vgqjLCKIpKHv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "gemini_key=userdata.get('GEMINI_KEY')"
      ],
      "metadata": {
        "id": "x1L_rbBwT-dT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "genai.configure(api_key=gemini_key)"
      ],
      "metadata": {
        "id": "3Fg5gYayWch6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=genai.GenerativeModel(\n",
        "    model_name=\"gemini-2.5-flash\",\n",
        "    generation_config={\n",
        "        \"temperature\":0,\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "id": "K9L8a8vYWuvt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response=model.generate_content(domain_prompt)\n",
        "ans=response.text\n",
        "print(ans)"
      ],
      "metadata": {
        "id": "KkwNvbsgXOAt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_summary_doc=make_doc(\n",
        "    text=ans,\n",
        "    username=user.login,\n",
        "    node_type=\"user_summary\"\n",
        ")\n",
        "# all_docs.append(user_summary_doc)\n",
        "print(type(all_docs[-1]))"
      ],
      "metadata": {
        "id": "KKkEUD7gaDrt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SETTING UP GEMINI FOR THE RAG"
      ],
      "metadata": {
        "id": "Tqs4HPRlbbbJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -q llama-index-llms-gemini\n"
      ],
      "metadata": {
        "id": "BFCElfkCfmY6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.llms.gemini import Gemini\n",
        "from google.colab import userdata\n",
        "# api_key=userdata.get(gemini_key)\n",
        "gemini_llm=Gemini(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    api_key=gemini_key,\n",
        "    temperature=0.5\n",
        ")"
      ],
      "metadata": {
        "id": "_VqWxBwqfFuI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import VectorStoreIndex\n",
        "embed_model=HuggingFaceEmbedding(\n",
        "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
        ")\n",
        "index=VectorStoreIndex(\n",
        "    all_docs,\n",
        "    embed_model=embed_model,\n",
        "    # llm=gemini_llm\n",
        ")\n",
        "# query_engine=index.as_query_engine(llm=gemini_llm)"
      ],
      "metadata": {
        "id": "NQAQ6wiJco1n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SETTING UP VALHALLA FOR QUESTION-NODE CONNECTION"
      ],
      "metadata": {
        "id": "hphh3G0Kbvm5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -q transformers torch"
      ],
      "metadata": {
        "id": "eI11unyHti92"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ROUTE_LABELS = [\n",
        "    \"global_profile_question\",\n",
        "    \"developer_overview\",\n",
        "    \"domain_expertise\",\n",
        "    \"repository_detail\",\n",
        "    \"contribution_behavior\"\n",
        "]\n",
        "LABEL_TO_NODE_TYPES = {\n",
        "  \"global_profile_question\": [\"user_profile\"],\n",
        "  \"developer_overview\": [\"user_profile\"],\n",
        "  \"repository_detail\": [\"repo_docs\"],\n",
        "  \"contribution_behavior\": [\"commit_docs\"]\n",
        "}\n"
      ],
      "metadata": {
        "id": "sICwADV60Ker"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "router = pipeline(\n",
        "    \"zero-shot-classification\",\n",
        "    model=\"valhalla/distilbart-mnli-12-1\",\n",
        "    device=-1\n",
        ")\n"
      ],
      "metadata": {
        "id": "G2Rw45vS0OPy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = router(\n",
        "    \"How many repositories does this developer have?\",\n",
        "    candidate_labels=ROUTE_LABELS\n",
        ")\n",
        "\n",
        "print(result)\n"
      ],
      "metadata": {
        "id": "F0ZD5nm81lpQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def route_question(question: str, threshold=0.23):\n",
        "    result = router(\n",
        "        question,\n",
        "        candidate_labels=ROUTE_LABELS,\n",
        "        multi_label=False\n",
        "    )\n",
        "\n",
        "    label = result[\"labels\"][0]\n",
        "    score = result[\"scores\"][0]\n",
        "\n",
        "    if score < threshold:\n",
        "        return None\n",
        "\n",
        "    return LABEL_TO_NODE_TYPES[label]\n",
        "print(route_question(\"Tell me about this user's repos\"))"
      ],
      "metadata": {
        "id": "v3m31HBH0RGD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "FINAL RAG"
      ],
      "metadata": {
        "id": "F2WlearQb0iZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.vector_stores.types import (\n",
        "    MetadataFilters,\n",
        "    MetadataFilter\n",
        ")\n",
        "question = \"Tell me about this user's repos\"\n",
        "\n",
        "node_types = route_question(question)\n",
        "\n",
        "if node_types:\n",
        "    filters = MetadataFilters(\n",
        "        filters=[MetadataFilter(key=\"type\", value=t) for t in node_types]\n",
        "    )\n",
        "    qe = index.as_query_engine(llm=gemini_llm, filters=filters)\n",
        "else:\n",
        "    qe = index.as_query_engine(llm=gemini_llm)\n",
        "retriever = index.as_retriever(\n",
        "    filters=filters,\n",
        "    similarity_top_k=5\n",
        ")\n",
        "\n",
        "nodes = retriever.retrieve(question)\n",
        "\n",
        "# print(\"NUMBER OF DOCS:\", len(nodes))\n",
        "# for i, n in enumerate(nodes):\n",
        "#     print(f\"\\n--- DOC {i} ---\")\n",
        "#     print(\"TYPE:\", n.node.metadata)\n",
        "#     print(\"TEXT LENGTH:\", len(n.node.text))\n",
        "#     print(n.node.text)\n",
        "\n",
        "print(qe.query(question))\n"
      ],
      "metadata": {
        "id": "5wQ8CsPX0r-w"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}